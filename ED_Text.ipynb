{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "# from torch.utils.data import DataLoader, Dataset\n",
        "# from torch.optim import AdamW\n",
        "# from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "oxUp5SZ26Xfq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load your dataset (use a sample if RAM is limited)\n",
        "# df = pd.read_parquet(\"/content/train-00000-of-00001.parquet\")\n",
        "\n",
        "# # Optional: Use 10% of the data for faster training\n",
        "# df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# # Split dataset into training and validation\n",
        "# train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "#     df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.1, stratify=df[\"label\"]\n",
        "# )\n",
        "\n",
        "# # Load MiniLM tokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"nreimers/MiniLM-L6-H384-uncased\")\n",
        "\n",
        "# # Tokenize the text data\n",
        "# train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=64)\n",
        "# val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=64)\n",
        "\n",
        "# # Convert tokenized data to PyTorch Dataset format\n",
        "# class EmotionDataset(Dataset):\n",
        "#     def __init__(self, encodings, labels):\n",
        "#         self.encodings = encodings\n",
        "#         self.labels = labels\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "#         item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "#         return item\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.labels)\n",
        "\n",
        "# train_dataset = EmotionDataset(train_encodings, train_labels)\n",
        "# val_dataset = EmotionDataset(val_encodings, val_labels)\n",
        "\n",
        "# # Create DataLoaders for batching\n",
        "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "# # Load MiniLM model for sequence classification\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"nreimers/MiniLM-L6-H384-uncased\", num_labels=6)\n",
        "\n",
        "# # Use AdamW optimizer and set a learning rate\n",
        "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# # Training loop\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# # Number of epochs\n",
        "# epochs = 3\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "#     correct_predictions = 0\n",
        "#     total_samples = 0\n",
        "\n",
        "#     for batch in train_loader:\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Move tensors to the same device as model\n",
        "#         input_ids = batch[\"input_ids\"].to(device)\n",
        "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
        "#         labels = batch[\"labels\"].to(device)\n",
        "\n",
        "#         # Forward pass\n",
        "#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "#         loss = outputs.loss\n",
        "#         logits = outputs.logits\n",
        "\n",
        "#         # Backward pass\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#         # Calculate accuracy\n",
        "#         _, predicted = torch.max(logits, dim=1)\n",
        "#         correct_predictions += (predicted == labels).sum().item()\n",
        "#         total_samples += labels.size(0)\n",
        "\n",
        "#     avg_loss = total_loss / len(train_loader)\n",
        "#     accuracy = correct_predictions / total_samples * 100\n",
        "#     print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "#     # Validation\n",
        "#     model.eval()\n",
        "#     val_loss = 0\n",
        "#     correct_predictions = 0\n",
        "#     total_samples = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for batch in val_loader:\n",
        "#             # Move tensors to the same device as model\n",
        "#             input_ids = batch[\"input_ids\"].to(device)\n",
        "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
        "#             labels = batch[\"labels\"].to(device)\n",
        "\n",
        "#             # Forward pass\n",
        "#             outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "#             loss = outputs.loss\n",
        "#             logits = outputs.logits\n",
        "\n",
        "#             val_loss += loss.item()\n",
        "\n",
        "#             # Calculate accuracy\n",
        "#             _, predicted = torch.max(logits, dim=1)\n",
        "#             correct_predictions += (predicted == labels).sum().item()\n",
        "#             total_samples += labels.size(0)\n",
        "\n",
        "#     avg_val_loss = val_loss / len(val_loader)\n",
        "#     val_accuracy = correct_predictions / total_samples * 100\n",
        "#     print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "ZKIl35VeT7Gc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"emotion_model\")\n",
        "# tokenizer.save_pretrained(\"emotion_model\")"
      ],
      "metadata": {
        "id": "eojR0viQhb8X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# # Create a zip file from the 'emotion_model' directory\n",
        "# shutil.make_archive(\"emotion_model\", 'zip', \"emotion_model\")"
      ],
      "metadata": {
        "id": "70scxSurhiGX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load model and tokenizer from saved directory\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/text_ED_model_MiniLM-L6-H384\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/text_ED_model_MiniLM-L6-H384\")\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgF0IkOliWr_",
        "outputId": "e258c483-3a25-4946-85cf-cc4756465b67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 384)\n",
              "      (token_type_embeddings): Embedding(2, 384)\n",
              "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=384, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "}"
      ],
      "metadata": {
        "id": "jXYmxgv1ibLX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(text):\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
        "\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    predicted_class = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return id2label[predicted_class], probs[0][predicted_class].item()"
      ],
      "metadata": {
        "id": "xmNhUqqiiduP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I’m really happy with the results!\"\n",
        "label, confidence = predict_emotion(text)\n",
        "print(f\"Predicted Emotion: {label} (Confidence: {confidence:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k-a90Nrig7n",
        "outputId": "d68cbd0a-3fd9-4d9a-d1d8-242613cc39d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: joy (Confidence: 0.94)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}